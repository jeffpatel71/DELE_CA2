{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n",
    "<!-- <h3>Base Model</h3> -->\n",
    "- Epsilon = 1\n",
    "- Epsilon_min = 0.01\n",
    "- Epsilon_decay = 0.99\n",
    "- Learning_rate = 0.01\n",
    "- Discount_rate = 0.8\n",
    "- Train_start = 1000\n",
    "- Batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, epsilon_decay=0.99, learning_rate=0.01, discount_rate=0.8, n_discrete_actions=10, weights=None):\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.render = False\n",
    "        self.epsilon = 1\n",
    "        self.epsilon_min = 0.01 \n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.MinMemory = 1000\n",
    "        self.EpsilonDecay = epsilon_decay \n",
    "        self.LearningRate = learning_rate \n",
    "        self.DiscountRate = discount_rate \n",
    "        self.BatchSize = 32\n",
    "        self.Optimiser = Adam(lr=self.LearningRate)\n",
    "        self.NActions = n_discrete_actions\n",
    "\n",
    "        self.Memory = deque(maxlen=3000)\n",
    "        # Build Main Model & Target Model\n",
    "        self.model = self.Build_Model()\n",
    "        if weights != None:\n",
    "            self.model.load_weights(weights)\n",
    "        self.t_model = self.Build_Model()\n",
    "        self.update_t_weights()\n",
    "\n",
    "    def Build_Model(self):\n",
    "\n",
    "        # inputs = Input(shape = (self.state_size), name = 'Input')\n",
    "        # x = Dense(24, activation = 'relu', name = '1stHiddenLayer')(inputs)\n",
    "        # x = Dense(24, activation = 'relu', name = '2ndHiddenLayer')(x)\n",
    "        # outputs = Dense(self.NActions, activation = 'linear', name = 'Output')(x)\n",
    "        \n",
    "        # NN = Model(inputs, outputs)\n",
    "        # NN.compile(loss = 'mse', optimizer = Adam(lr = self.LearningRate))\n",
    "        # NN.summary()\n",
    "\n",
    "\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(1,3), name=\"Input_Layer\"))\n",
    "        model.add(Dense(24, activation=\"relu\"))\n",
    "        model.add(Dense(24, activation=\"relu\"))\n",
    "        model.add(Dense(self.NActions, activation=\"linear\"))\n",
    "        model.summary()\n",
    "        model.compile(loss=\"mse\", optimizer=Adam(lr=self.LearningRate))\n",
    "        return model \n",
    "            \n",
    "    def UpdateMemory(self, state, action, reward, next_state, done):\n",
    "        # Replay Buffer\n",
    "        self.Memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def update_t_weights(self):\n",
    "        # Update Target Model\n",
    "        self.t_model.set_weights(self.model.get_weights())\n",
    "    \n",
    "    def PendulumActionConverter(self, A):\n",
    "        ActualTorque = (A / self.NActions - 0.5) * 4\n",
    "        return ActualTorque\n",
    "\n",
    "    def PendulumInverseActionConverter(self, A):\n",
    "        ActualA = round((A + 2) * (self.NActions - 1) / 4)\n",
    "        return  (ActualA)\n",
    "\n",
    "    def Get_Action(self, state, env):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            action = env.action_space.sample()\n",
    "            a = self.PendulumInverseActionConverter(action[0])\n",
    "            return action, a\n",
    "        else:\n",
    "            q_values = self.model(state).numpy() \n",
    "            step = np.argmax(q_values[0])\n",
    "            a = self.PendulumActionConverter(a)\n",
    "            action = np.array([a])\n",
    "            a = self.PendulumInverseActionConverter(step)\n",
    "            return action, a\n",
    "        \n",
    "    def Train(self):\n",
    "        # Only train if replay memory has enough data. #\n",
    "        if len(self.Memory) < self.MinMemory:\n",
    "            # print(f'DID NOT TRAIN..., replay memory = {len(self.Memory)}')\n",
    "            return\n",
    "        \n",
    "        # Get batch of data for training. #\n",
    "        TrainingData = random.sample(self.Memory, self.BatchSize)\n",
    "        \n",
    "        # Get states from training data, then get corresponding Q values. #\n",
    "        ListOfS = np.array([element[0] for element in TrainingData])\n",
    "        ListOfQ = np.array([element[0] for element in self.model(ListOfS)])\n",
    "    \n",
    "        print(ListOfQ)\n",
    "        # ListOfQ = ListOfQ[0]\n",
    "        # print(ListOfQ)\n",
    "\n",
    "        # Get future states from training data, then get corresponding Q values. #\n",
    "        ListOfSNext = np.array([element[3] for element in TrainingData])\n",
    "        ListOfQNext = self.t_model(ListOfSNext)\n",
    "        \n",
    "        # Build actual training data for neural network. #\n",
    "        X = []\n",
    "        Y = []\n",
    "        for index, (S, A, R, SNext, Done) in enumerate(TrainingData):\n",
    "            if not Done:\n",
    "                MaxQNext = np.max(ListOfQNext[index])\n",
    "                QNext = R + self.epsilon * MaxQNext\n",
    "            else:\n",
    "                QNext = R\n",
    "            Q = ListOfQ[index]\n",
    "            Q[A] = QNext\n",
    "            X.append(S)\n",
    "            Y.append(Q)\n",
    "        \n",
    "        # Train model using tf.GradientTape(), defined below.\n",
    "        self.GTfit(X, Y)\n",
    "    \n",
    "    @tf.function\n",
    "    def GTfit(self, X, Y):\n",
    "        # Train the neural network with this batch of data. #\n",
    "        with tf.GradientTape() as tape:\n",
    "            Predictions = self.model(tf.convert_to_tensor(X), training = True)\n",
    "            Loss = tf.math.reduce_mean(tf.math.square(tf.convert_to_tensor(Y) - Predictions))\n",
    "        Grad = tape.gradient(Loss, self.model.trainable_variables)\n",
    "        self.Optimiser.apply_gradients(zip(Grad, self.model.trainable_variables))\n",
    "\n",
    "def main(epsilon_decay=0.99, learning_rate=0.01, discount_rate=0.8, bins=10,filename=\"base_reward.h5\", weights=None):\n",
    "    \n",
    "    env = gym.make(\"Pendulum-v0\")\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    agent = DQNAgent(state_size, epsilon_decay=epsilon_decay, learning_rate=learning_rate, discount_rate=discount_rate, n_discrete_actions=bins, weights=weights)\n",
    "    \n",
    "    scores = []\n",
    "    avg_score = []\n",
    "    best_score = -np.inf\n",
    "\n",
    "    for e in range(4):\n",
    "\n",
    "        done = False\n",
    "        score = 0\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            \n",
    "            action, a = agent.Get_Action(state, env)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "\n",
    "            agent.UpdateMemory(state, a, reward, next_state, done)\n",
    "            agent.Train()\n",
    "\n",
    "            score += reward\n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                scores.append(score) # Save the score\n",
    "                avg_score.append(np.mean(scores[-100:])) # Moving Average Score\n",
    "\n",
    "                print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                      len(agent.Memory), \"  epsilon:\", agent.epsilon)\n",
    "\n",
    "    env.close() \n",
    "    return avg_score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 1, 24)             96        \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1, 24)             600       \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 1, 10)             250       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 946 (3.70 KB)\n",
      "Trainable params: 946 (3.70 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_83 (Dense)            (None, 1, 24)             96        \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 1, 24)             600       \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 1, 10)             250       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 946 (3.70 KB)\n",
      "Trainable params: 946 (3.70 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   score: -1173.5639201812385   memory length: 200   epsilon: 1\n",
      "episode: 1   score: -1340.446681800306   memory length: 400   epsilon: 1\n",
      "episode: 2   score: -1314.0007528072442   memory length: 600   epsilon: 1\n",
      "episode: 3   score: -1476.6832877709892   memory length: 800   epsilon: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-1173.5639201812385,\n",
       "  -1257.0053009907722,\n",
       "  -1276.0037849295961,\n",
       "  -1326.1736606399445],\n",
       " [-1173.5639201812385,\n",
       "  -1340.446681800306,\n",
       "  -1314.0007528072442,\n",
       "  -1476.6832877709892])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hazem\\anaconda3\\envs\\RL\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 24)                96        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                600       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                600       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1296 (5.06 KB)\n",
      "Trainable params: 1296 (5.06 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(1,3), name=\"Input_Layer\"))\n",
    "model.add(Dense(24, activation=\"relu\"))\n",
    "model.add(Dense(24, activation=\"relu\"))\n",
    "model.add(Dense(24, activation=\"linear\"))\n",
    "model.summary()\n",
    "model.compile(loss=\"mse\", optimizer=Adam(lr=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 24)                96        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 24)                600       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 40)                1000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1696 (6.62 KB)\n",
      "Trainable params: 1696 (6.62 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "input_layer = Input(shape=(3,))\n",
    "hidden_layer_1 = Dense(24, activation=\"relu\")(input_layer)\n",
    "hidden_layer_2 = Dense(24, activation=\"relu\")(hidden_layer_1)\n",
    "output_layer = Dense(40, activation=\"linear\")(hidden_layer_2)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
